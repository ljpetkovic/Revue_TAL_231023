L’extraction d'informations de grands volumes de données issus de la numérisation et de la reconnaissance optique de caractères (OCR) suscite la réflexion quant à la possibilité de récupérer des informations exploitables scientifiquement de ces données bruitées. Le bruit désigne dans ce cas toutes les erreurs produites par le système OCR : l'insertion, la suppression, mais aussi la substitution d'un ou plusieurs caractères par d'autres. 
Les chercheurs sont ainsi confrontés aux difficultés d'appliquer des outils informatiques généralement entraînés sur des données textuelles correctement orthographiées \cite{https://doi.org/10.48550/arxiv.1706.09147}, à des données textuelles moins standardisées. 
Un des remèdes consiste à corriger les données délivrées par l'OCR, idéalement automatiquement, avant de les soumettre à un outil de traitement automatique du langage (TAL).
Or, si certaines erreurs produites par les dispositifs d'OCR sont systématiques \cite{stanislawek-2019}, lorsqu'il s’agit d’erreurs singulières cet exercice devient difficile à effectuer, en outre la correction peut, elle aussi, produire des erreurs \cite{huynh:hal-03034484}.
 
 
La Reconnaissance d'entités nommées (REN) est une des tâches de TAL permettant d'extraire des connaissances de ces vastes corpus de textes (\cite{chiron:hal-03025508} et \cite{linharespontes}). En effet, les entités nommées (EN) et particulièrement les EN de lieux \cite{vanStrien-2020} constituent la majorité des requêtes formulées par les utilisateurs. L’identification des EN serait un moyen efficace d’améliorer l’accès aux données. 
Dès lors, la question principale concerne l'évaluation de l'incidence des erreurs d'OCR sur la REN spatiale \cite{hamdi:hal-03026931}, et l'influence de ce bruit sur les usages consécutifs \cite{vanStrien-2020} de ces données. 
Dans le même temps, \cite{DBLP:conf/gis/Koudoro-Parfait21} produisent une analyse automatique des sorties d'outils de REN tels que \textsc{spaCy} \cite{honnibal2017spacy} et \textsc{stanza}\cite{qi2020stanza}.

%COMMENT met-on les liens web ?  \url{] provoque une erreur, usepackage hyperref semble provoquer des problèmes !%
Leurs analyses s'appuient sur le corpus français de la collection ELTeC - European collection of literary texts\footnote{European collection of literary texts : \url{https://www.distant-reading.net/eltec/}} et comparent la REN sur cette version de référence, aux sorties obtenues par transcription OCR. Ils démontrent que certains outils de REN prêts à l'emploi sont plutôt robustes face aux variabilités auxquelles les systèmes sont confrontés : contextes et EN \textit{contaminés} (terme proposé par \cite{hamdi:hal-03615997}) par différentes erreurs d'OCR. 
Du fait des problèmes d'alignement entre les EN de la version de référence et celles de la version OCR, cette analyse reste limitée à un point de vue global, qui ne permet pas de rapprocher les formes contaminées des formes de référence. Par la suite, \cite{koudoro2022reconnaissance} proposent de produire une analyse automatique plus précise en utilisant deux méthodes pour aligner des entités contaminées à l'EN de référence, c'est-à-dire aligner des EN qui ont la même graphie ou une graphie proche, par exemple aligner "\textit{Saint-Nizier}" avec "\textit{Saint-Nizier.n}" et "\textit{Saint-Nizierl}".
Dans un premier temps, ils utilisent le système \textsc{Nerval}\footnote{\url{https://gitlab.com/teklia/nerval}} pour l'alignement d'EN bruitées, qui s'appuie sur une distance de Levenshtein. Après avoir déterminé que cet outil, bien que plutôt efficace, possède quelques biais, ils proposent une solution utilisant une distance Cosinus moins coûteuse en temps de calcul. 
La tâche d'alignement des EN, nous interroge quant aux divers algorithmes de calcul de distance (Bray-Curtis, Cosinus, Jaccard) et la méthode du clustering de données en particulier (\cite{lin-1998-automatic} et \cite{green-etal-2012-entity}). Le clustering de données textuelles fournit une représentation numérale et condensée de celles-ci \cite{Loustau2013} et pourrait être appliqué sur des données bruitées \cite{brunet:hal-00851484}. L'usage de cette méthode permettrait de regrouper les formes contaminées d'une même EN sans avoir accès à l'EN de référence. Nous menons notre expérience de clustering sur les résultats de \textsc{spaCy}, \textsc{stanza}, \textsc{sem}\footnote{https://github.com/YoannDupont/SEM et https://www.lattice.cnrs.fr/sites/itellier/SEM.html} \cite{dupont-tellier:2014:TALN} et \textsc{CasEn}\footnote{https://tln.lifat.univ-tours.fr/version-francaise/ressources/casen} \cite{maurel:hal-00682805}. Le recours à ces deux derniers outils vient consolider la réflexion autour des usages de \textit{systèmes clé en main} pour le français. Nous utilisons le corpus français\footnote{https://github.com/These-SCAI2023/NER\_GEO\_COMPAR} constitué par \cite{DBLP:conf/gis/Koudoro-Parfait21}. Ce corpus comprend une dizaine de textes de références en français et leurs versions OCRisées avec kraken\footnote{\url{https://github.com/mittagessen/kraken}} et le modèle français de Tesseract\footnote{\url{https://github.com/tesseract-ocr/tesseract}} \cite{smith2007overview}.